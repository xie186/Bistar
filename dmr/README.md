
# Bistar: differential methylation analysis pipeline

## Table of contents

* [Description](#description)
    * [Steps of the pipeline](#steps-of-the-pipeline)
* [Covariates](#covariates)
    * [Example of covariate file](#example-of-covariate-file)
* [Creation of configuration files](#creation-of-configuration-files)
    * [List the files to process](#list-the-files-to-process)
    * [Required settings](#required-settings)
    * [Optional settings](#optional-settings)
    * [Example of configuration file creation](#example-of-configuration-file-creation)
* [How to run](#how-to-run)
    * [Running on a workstation](#running-on-a-workstation)
    * [Running on a SLURM cluster](#running-on-a-slurm-cluster)

## Description

This pipeline computes differentially methylated regions (DMRs) from CpG methylation
counts. These methylation counts are assumed to be
[Bismark](https://www.bioinformatics.babraham.ac.uk/projects/bismark/) CpG report
files generated by the [preprocessing pipeline](../preproc/README.md).

### Steps of the pipeline
1. Load methylation counts and covariates into R as a
   [BSseq](https://github.com/hansenlab/bsseq) object and save the result as a
   R data file: *bs.rds*.
2. Compute the PCA and hierarchical clustering of methylation counts for CpGs
   that are measured in all samples and create a PNG plot.
3. Compute the differentially methylated regions with [dmrseq](https://github.com/kdkorthauer/dmrseq).
4. Annotate the DMRs with [Goldmine](https://github.com/jeffbhasin/goldmine)

The pipeline is provided as 7 files and one directory with annotation files:

| File | Description |
| ---- | ----------- |
| [README.md](README.md) | This documentation. |
| [create_dmr_config.py](create_dmr_config.py) | Script that helps creating the pipeline's configuration files so that the user can specify what to process and how. |
| [create_bsseq_object.R](create_bsseq_object.R) | R script computing step 1. |
| [clustering_of_methylation_ratios.R](pca_of_methylation_ratios.R) | R script computing step 2. |
| [dmrseq.R](dmrseq.R) | R script computing step 3. |
| [annotate_dmrs.R](annotate_dmrs.R) | R script computing step 4. |
| [Snakefile_dmr](Snakefile_dmr) | The [Snakemake](https://snakemake.readthedocs.io/en/stable/) workflow. |
| [Goldmine](../Goldmine) | Directory that provides pre-downloaded [UCSC](https://genome.ucsc.edu/) hg19 and mm10 gene tables. You can use it as cache directory for [Goldmine](https://github.com/jeffbhasin/goldmine) to avoid re-downloading the annotation files by passing '--goldmine-dir $BISTAR_DIR/goldmine' when calling create_dmr_config.py |

## Covariates

The covariates have to be provided as a TSV (tab-separated values) file with at
least the test covariate and optionally other covariates to be accounted for.
The file has to be tab-separated with a header with the name(s) of the covariate(s).
The first column has to be the list of the sample IDs, the name of this column
will be ignored. [dmrseq](https://github.com/kdkorthauer/dmrseq) is flexible,
a covariate can be numerical or categorical, even with more than 2 levels.

### Example of covariate file

The order of covariates is not important. Here the first covariate is categorical
with 2 levels and the second is continuous. They can both be used as the test
covariate by [dmrseq](https://github.com/kdkorthauer/dmrseq).

```
sample	covariate1	covariate2
S1	groupA	20
S2	groupB	60
S3	groupB	75
S4	groupB	80
S5	groupA	35
```


## Creation of configuration files

The pipeline works with 2 YAML configuration files that are created by the provided
Python script:
- *dmr\_config.yaml*: general configuration file with the parameters, the files
  to process and the associated sample IDs.
- *dmr\_cluster\_config.yaml*: used if you run on a cluster to adapt the amount
  of ressources that are requested to the cluster for each step of the pipeline.
  You can edit it to adapt the number of CPUs, wall time or memory consumption.

Asumming you are in the *Bistar* environment, you can list all the available
options that can be set and for optional parameters their default value:
```bash
create_dmr_config.py --help
```

The default dmrseq parameters used in the script are dmrseq's default values,
they were set for human whole genome sequencing. For other types of sequencing
(e.g. targeted) or other species the parameters should probably be adjusted.

### List the files to process

Similarly to the preprocessing pipeline, you don't explicitly provide a least of
files to process, instead you have to provide a Snakemake regular expression from
which the Bismark CpG report files and the associated sample IDs are inferred.

#### Example

Assuming that you want to process these 4 files:

    /dir1/dir2/S1/S1.deduplicated.CpG_report.txt.gz
    /dir1/dir2/S2/S2.deduplicated.CpG_report.txt.gz
    /dir1/dir2/S3/S3.deduplicated.CpG_report.txt.gz
    /dir1/dir2/S4/S4.deduplicated.CpG_report.txt.gz

the regular expression would be:

    /dir1/dir2/{sample}/{sample}.deduplicated.CpG_report.txt.gz

'{sample}' is the only required wildcard but like for the preprocessing pipeline,
if you have other variable fields in the filepath you can define arbitrary wildcards
to match them (see [Example 3](../preproc/README.md#example-3) of the
[preprocessing pipeline](../preproc/README.md)).

### Required settings

| Argument | Description |
| -------- | ----------- |
| --cpg-report-regex | Snakemake regex used to infer the Bismark CpG report files to process and the related sample IDs. The '{sample}' wildcard is required in the regex. Arbitrary wildcards can be used to match for variable fields in the filepath. Examples: '/path/to/data/{sample}/{sample}.CpG_report.txt.gz' or '/path/to/data/{sample}_{ignore}.CpG_report.txt.gz'. |
| --outdir | Output directory. |
| --ref-build | Reference genome build, e.g. hg19 or mm10. The Goldmine annotation will only work if the reference build name is a UCSC genome name. |
| --covariates-tsv | Path to the covariate file, providing the test covariate and optionally the covariates to be accounted for. The file has to be tab-separated with a header with the name(s) of the covariate(s). The first column provides the sample IDs. |
|--test-covariate  | dmrseq 'testCovariate' argument: the name of the covariate to test for association of methylation levels. Two-group comparison is carried out if the variable has 2 levels, but dmrseq can also work with continuous or categorical variables that have more than 2 levels. Check dmrseq's documentation. |

### Optional setting

| Argument | Description |
| -------- | ----------- |
| --bsseq-threads | Number of threads to use when loading methylation counts with BSseq by default 1. Increasing the number of threads increases RAM consumption. |
| --dmrseq-threads | dmrseq 'threads' argument, by default 1. Increasing the number of threads increases RAM consumption. |
| --do-not-merge-complementary-cpgs | By default a CpG and its complementary CpG on the other strand are merged as one CpG because we consider methylation as symmetric. Set this flag to keep 2 separate CpGs. |
| --max-gap | dmrseq 'maxGap' argument: max basepair distance between neighboring CpGs to be included in the same DMR, by default 100. |
| --min-cpgs |  dmrseq 'minNumRegion' argument: minimum number of CpGs in a DMR, by default 5. |
| --min-samples | Minimum number of measured samples, otherwise the CpG is removed, by default 2. |
| --cutoff | dmrseq 'cutoff' argument, by default 0.1 . |
| --no-smoothing | Set dmrseq 'smooth' argument to False. |
| --bp-span | dmrseq 'bpSpan' argument: smoothing window in basepairs, by default 1000. |
| --min-in-span | dmrseq 'minInSpan' argument: minimum numober of CpGs in a smoothing span window, by default 30. |
| --max-gap-smooth | dmrseq 'maxGapSmooth' argument: max basepair distance between neighboring CpGs when smoothing, by default 2500. |
| --max-perms | dmrseq 'maxPerms' argument: maximum number of permutations to generate the global null distribution, by default 10. |
| --adjust-covariates | dmrseq 'adjusteCovariate' argument: the names of the covariates to be adjusted for when testing for the association of methylation value with the test covariate. |
| --match-covariate | dmrseq 'matchCovariate' argument: a covariate that will be blocked when permutating to test for the association of methylation with the test covariate. Only permutations with balanced composition of 'matchCovariate' will be used. Only possible for a two-group comparison and for one covariate. |
| --goldmine-dir | Directory to use a cache directory for Goldmine annotation package. It avoids re-downloading annotation databases from UCSC if you already have them. By default ${BISTAR_DIR}/goldmine |
| --goldmine-sync | Check if newer versions of UCSC annotation tables are available and if so download them in <--goldmine-dir>. It requires a web connection which is not always the case if you run on a cluster. |

### Example of configuration file creation

Example with targeted by capture sequencing, here we have decided to set *--max-gap*,
*--bp-span*, *--min-in-span* and *--max-gap-smooth* to values lower that the defaults
dmrseq's values because we work with smaller regions of higher coverage comparing
to whole-genome sequencing. More smoothing would have probably been needed if
measures were missing (to interpolate the signal across missing loci) or if measures
had low coverage (to smooth the noisy signal).

```bash
# Using a shell variable or adapt the following commands
DMR_OUTDIR=/path/to/dmr/outdir

create_dmr_config.py \
    --cpg-report-regex /dir1/dir2/{sample}/{sample}.merged_lanes.deduplicated.CpG_report.txt.gz \
    --covariates-tsv /dir1/dir2/covariates.tsv \
    --test-covariate condition \
    --outdir $DMR_OUTDIR \
    --ref-build hg19 \
    --min-samples 5 \
    --threads 4 \
    --cutoff 0.1 \
    --max-perms 10 \
    --min-cpgs 5 \
    --max-gap 100 \
    --bp-span 500 \
    --min-in-span 10 \
    --max-gap-smooth 1000
```

## Execution time and memory

More than 99% of the execution time is the computation of DMRs by dmrseq. Using
more threads will decrease the computation time but will increase the RAM
consumption. By multiplying the number of threads by N you roughly multiply the
RAM consumption by N. You are generally limited by the RAM consumption and cannot
allocate as many threads as you have CPUs whether it is on your workstation or
a node of your cluster.

Examples of memory and time consumptions of dmrseq:

| # samples | # threads | max perms | max RAM consumption | execution time |     # CpGs     |
| :-------: | :-------: | :-------: | :-----------------: | :------------: | :------------: |
|     16    |     1     |     10    |         71 GB       |        8h      | ~ 7.3 millions |


## How to run

Assuming that the *Bistar* environment is activated and the configuration files
have been created (at least *dmr_config.yaml* if you don't run on a cluster).

### Running on a workstation

```bash
# Dry run to check, remove --dryrun to run
snakemake \
    --jobs 1 \
    --configfile ${DMR_OUTDIR}/dmr_config.yaml \
    --snakefile ${$BISTAR_DIR}/dmr/Snakefile_dmr \
    --printshellcmds \
    --keep-going \
    --dryrun
```

Changing the *--jobs* argument to more than 1 is not going to significantly affect
the execution time, it allows to run multiple steps of the pipeline simultaneously.
Only dmrseq and the clustering could be run simultaneously.

The $BISTAR_DIR environment variable is created automatically when you install
Bistar you don't need to set it.

### Running on a cluster

Like for the preprocessing pipeline, the example bellow is for a SLURM cluster,
if you are using another scheduler you have to adapt the '--cluster' argument
with the command used on your cluster to create a job for a shellscript. Snakemake
will automatically replace the variables '{cluster.<variable>}' with the value
found in *dmr_cluster_config.yaml* for each step.

You can edit the *dmr_cluster_config.yaml* file to adapt the number of CPUs,
wall time or RAM memory that are requested to the cluster for each step of the
pipeline. Note that if you change the number of CPUs requested for a given step
it should be consistent with the number of threads used in the command which is
provided by the *dmr_config.yaml* configuration file. The default values for
memory and walltime were set to be largely enough when using 8 threads for all
steps on our internal projects: targeted sequencing with ~5 million CpGs.

The complete pipeline can be run in one command
```bash
# Dry run to check, remove --dryrun to run
snakemake \
    --configfile ${DMR_OUTDIR}/dmr_config.yaml \
    --cluster-config ${DMR_OUTDIR}/dmr_cluster_config.yaml \
    --snakefile ${BISTAR_DIR}/dmr/Snakefile_dmr \
    --jobs 1 \
    --cluster "sbatch --verbose \
                      --account=bioinfo \
                      --partition=normal \
                      --time={cluster.walltime} \
                      --mem={cluster.mem_gb}G \
                      --cpus-per-task={cluster.cpus} \
                      --output={cluster.stdout} \
                      --error={cluster.stderr}" \
    --printshellcmds \
    --latency-wait 60 \
    --keep-going \
    --dryrun
```

The annotation step with Goldmine requires a web connection to download the annotation
files, except if you work with the hg19 or mm10 reference builds (pre-downloaded
tables are in the package) and if you didn't request to check for annotation
updates (i.e. without *--goldmine-sync* flag when calling *create_dmr_config.py*).
It is common for a cluster's nodes to not have access to the web, then this step
would crash. You can run everything except annotation with the following command.

```bash
# Dry run to check, remove --dryrun to run
snakemake all_except_annotation \
    --configfile ${DMR_OUTDIR}/dmr_config.yaml \
    --cluster-config ${DMR_OUTDIR}/dmr_cluster_config.yaml \
    --snakefile ${BISTAR_DIR}/dmr/Snakefile_dmr \
    --jobs 1 \
    --cluster "sbatch --verbose \
                      --account=${ACCOUNT} \
                      --partition=${PARTITION} \
                      --time={cluster.walltime} \
                      --mem={cluster.mem_gb}G \
                      --cpus-per-task={cluster.cpus} \
                      --output={cluster.stdout} \
                      --error={cluster.stderr}" \
    --printshellcmds \
    --latency-wait 60 \
    --keep-going \
    --dryrun
```

Then run annotation. It could even be done on the frontal node of your cluster
since it takes less than a minute and does not consume a significant amount of
RAM (as long as you don't have tens of thousands of DMRs).
```bash
# Dry run to check, remove --dryrun to run
snakemake annotate_dmrs \
    --configfile ${DMR_OUTDIR}/dmr_config.yaml \
    --snakefile ${BISTAR_DIR}/dmr/Snakefile_dmr \
    --jobs 1 \
    --printshellcmds \
    --dryrun
```
